# Tabajo 1

## Calibraci贸n de la camara

Para la calibraci贸n de la c谩mara se sigui贸 la guia de GeeksforGeeks (s.f.), con el cual se obtuvieron los siguientes resultados.

La funci贸n cv2.drawChessboardCorners() desempe帽a un papel crucial al visualizar y verificar el 茅xito de la detecci贸n de esquinas en la imagen, asegurando la calidad de los puntos de referencia. Se emple贸 la siguiente l铆nea de c贸digo para la visualizaci贸n:

```python
# Dibujar y mostrar las esquinas en la imagen
image = cv2.drawChessboardCorners(image, 
                                  CHECKERBOARD, 
                                  corners2, ret)
```
En la Figura 1 se muestran cuatro de las im谩genes utilizadas con las esquinas detectadas. Esta detecci贸n es esencial, ya que estos puntos proporcionan las coordenadas de referencia precisas necesarias para el algoritmo de calibraci贸n de la c谩mara.

<table>
  <caption>
    <strong>Figura 1:</strong> Tableros de ajedrez con las esquinas detectadas.
  </caption>
  <tr>
    <td style="text-align: center;">
      <img src="..\Taller 1\Puntos_detectados\detected_imagen5.jpeg" width="90%" alt="Imagen 1">
      <p><strong>Figura 1.a</strong></p>
    </td>
    <td style="text-align: center;">
      <img src="../Taller 1\Puntos_detectados\detected_imagen3.jpeg" width="90%" alt="Imagen 2">
      <p><strong>Figura 1.b</strong> </p>
    </td>
  </tr>
  <tr>
    <td style="text-align: center;">
      <img src="../Taller 1\Puntos_detectados\detected_imagen7.jpeg" width="90%" alt="Imagen 3">
      <p><strong>Figura 1.c</strong></p>
    </td>
    <td style="text-align: center;">
      <img src="../Taller 1\Puntos_detectados\detected_imagen6.jpeg" width="90%" alt="Imagen 4">
      <p><strong>Figura 1.d</strong> </p>
    </td>
  </tr>
</table>

El objetivo principal de la calibraci贸n es obtener la estimaci贸n de los par谩metros que transforman una coordenada del mundo real (3D) en una coordenada de p铆xel en la imagen (2D). Para ello, se determinaron la matriz intr铆nseca de la c谩mara y los coeficientes de distorsi贸n.

**Ecuaci贸n 1:** Matriz Intr铆nseca de la C谩mara ($\mathbf{K}$)

$$
\mathbf{K} = \begin{bmatrix}
1.344 \times 10^{3} & 0.0 & 801.86 \\
0.0 & 1.351 \times 10^{3} & 613.08 \\
0.0 & 0.0 & 1.0
\end{bmatrix}
$$

De la Ecuaci贸n 1 se obtine la  observar la Matriz Intr铆nseca de la c谩mara que esta compuesta por las longitudes focales $f_x$ y $f_y$, y las cordenadas $c_x$ y $c_y$ del centro 贸ptico.  
Se observar que $f_x \approx 1344.23 \text{ p铆xeles}$ y $f_y \approx 1350.77 \text{ p铆xeles}$, la diferencia  aproximadamente 6.5 p铆xeles entre los ejes focales representa menos del $1\%$ del valor total, lo que confirma que la camara utiliza p铆xeles cuadrados, si esta diferencia resulta ser significativamente mayor ya estariamos hablando de p铆xeles rectangulares o que hay un problema, ya sea de aliasing (p铆xeles de un sensor es demasiado grande en comparaci贸n con los detalles finos de la escena) o escalado en la lectura del sensor. Respecto al centro 贸ptico, los puntos $c_x = 801.86 \text{ p铆xeles}$ y $c_y = 613.08 \text{ p铆xeles}$ se encuentran muy pr贸ximos al centro geom茅trico te贸rico de la imagen $(800.0, 600.0)$. El desplazamiento es m铆nimo, siendo de $1.86 \text{ p铆xeles}$ en $x$ y $13.08 \text{ p铆xeles}$ en $y$.

$$\text{Error RMS Total} = \frac{1}{N} \sum_{i=1}^{N} \left( \frac{1}{M_{i}} \sum_{j=1}^{M_{i}} \left\| \mathbf{m}_{i, j} - \mathbf{\hat{m}}_{i, j} \right\| \right)$$

Caption 1. F贸rmula utilizada para calcular el Error RMS Total de Reproyecci贸n. $N$ es el n煤mero total de im谩genes; $M_i$ es el n煤mero de puntos detectados en la imagen $i$; $\mathbf{m}_{i, j}$ es la coordenada 2D real (observada) del punto; y $\mathbf{\hat{m}}_{i, j}$ es la coordenada 2D predicha (reproyectada) por el modelo de la c谩mara.

El RMS obtenido fue de $0.495 \text{ p铆xeles}$, que es menor al umbral de $0.5 \text{ p铆xeles}$. Esto quiere decir que la ubicaci贸n real de las esquinas en la imagen y la ubicaci贸n predicha por el modelo matem谩tico de la c谩mara difieren en menos de medio p铆xel.

**Ecuaci贸n 2:** Vector de Coeficientes de Distorsi贸n ($\mathbf{D}$)

$$
\mathbf{D} = \begin{pmatrix}
2.771 \times 10^{-1} & -1.895 & -7.036 \times 10^{-5} & 5.678 \times 10^{-4} & 4.138
\end{pmatrix}
$$

En la Ecuaci贸n 2 se obtienen los coheficinetes de distorci贸n $k_1 = 0.277$ de primer orden, $k_2 = -1.895 $, $p_1 = -7.036 \times 10^{-5 } $ de segundo orden y $k_3 = 4.138$ de tercer orden. Cuando $k_1$ es negativo predomina la distorcion barril (las lineas se curvan hacia afuera), pero cuando $k_1$ es positivo se espera tener una distorsion cojin (las lineas se curvan hacia adentro). Como el coeficiente $k_1 > 0$ se espera que las imagenes muestren una distorsion cojin. 

Respecto a los coeficientes de distorsi贸n, se observa lo siguiente:

- Coeficiente $k_2$: Al ser un valor negativo, $k_2$ est谩 actuando como un compensador o corrector para mitigar el efecto de una potencial subcorrecci贸n (o sobrecorrecci贸n) generada por $k_1$.

- Coeficiente $k_3$: El valor de $k_3$ es significativamente grande. Esto indica que la distorsi贸n de la lente es compleja o fuerte, lo que sugiere que el modelo de calibraci贸n no logr贸 un ajuste preciso de la distorsi贸n utilizando 煤nicamente los coeficientes $k_1$ y $k_2$.

Los par谩metros $p_1$ y $p_2$ miden la distorsi贸n tangencial, la cual provoca que un punto en el mundo real se proyecte en la imagen con un peque帽o desplazamiento asim茅trico a lo largo de un vector que no es puramente radial.

Los valores obtenidos son: $p_1 = -7.036 \times 10^{-5}$ y $p_2 = 5.678 \times 10^{-4}$.

Al ser valores tan peque帽os, esto demuestra una alineaci贸n f铆sica casi perfecta entre el eje 贸ptico de la lente y el sensor de la c谩mara, un factor ideal para la visi贸n artificial de precisi贸n.

<h4>Figura 2: Comparaci贸n de Im谩genes (Original vs. Corregida)</h4>
<div style="display: grid; grid-template-columns: 50% 50%; gap: 10px;">
    
<!-- PAR 1 -->
<div style="text-align: center;">
    <img src="../Taller 1/Imagenes_calibracion/imagen2.jpeg" width="100%" alt="Imagen Original 1">
    <p><strong>(a.1) Original</strong></p>
</div>
<div style="text-align: center;">
    <img src="../Taller 1/Imagenes_corregidas/undistorted_imagen2.jpeg" width="100%" alt="Imagen Corregida 1">
    <p><strong>(b.1) Corregida</strong></p>
</div>

<!-- PAR 2 -->
<div style="text-align: center;">
    <img src="../Taller 1/Imagenes_calibracion/imagen3.jpeg" width="100%" alt="Imagen Original 2">
    <p><strong>(a.2) Original</strong></p>
</div>
<div style="text-align: center;">
    <img src="../Taller 1/Imagenes_corregidas/undistorted_imagen3.jpeg" width="100%" alt="Imagen Corregida 2">
    <p><strong>(b.2) Corregida</strong></p>
</div>

<!-- PAR 3 -->
<div style="text-align: center;">
    <img src="../Taller 1/Imagenes_calibracion/imagen7.jpeg" width="100%" alt="Imagen Original 3">
    <p><strong>(a.3) Original</strong></p>
</div>
<div style="text-align: center;">
    <img src="../Taller 1/Imagenes_corregidas/undistorted_imagen7.jpeg" width="100%" alt="Imagen Corregida 3">
    <p><strong>(b.3) Corregida</strong></p>
</div>
</div>

La correcci贸n de la distorsi贸n radial se evalu贸 con especial atenci贸n en las esquinas, ya que esta distorsi贸n aumenta proporcionalmente con la distancia al centro 贸ptico $()$, lo que hace que dicha zona requiera el mayor desplazamiento de p铆xeles. Visualmente, la Figura 2 confirma el 茅xito, mostrando que las l铆neas del tablero, que en la imagen original se curvaban hacia el interior (distorsi贸n de tipo coj铆n), ahora son segmentos perfectamente rectos y paralelos, incluso en los bordes extremos. Esta correcci贸n robusta est谩 respaldada por el bajo error RMS de reproyecci贸n $(0.495px)$, lo que indica que la predicci贸n de la posici贸n de cada punto, incluidos los de las esquinas, se logr贸 con una precisi贸n subp铆xel.



## 3. Implementar y aplicar transformaciones de rotaci贸n y traslaci贸n



Creen una funci贸n que:

* **Cargue una imagen**
* **Aplique 5-8 transformaciones sucesivas** (traslaciones, rotaciones, escalas)
* **Genere un GIF animado o video** mostrando la secuencia
* **Guarden cada frame intermedio**


---
### Contexto

En el **procesamiento digital de im谩genes**, las **transformaciones geom茅tricas** son operaciones que permiten modificar la posici贸n, orientaci贸n o tama帽o de los objetos dentro de una imagen. Entre las m谩s comunes se encuentran la **traslaci贸n**, la **rotaci贸n** y la **escala**.

Estas operaciones son fundamentales en 谩reas como **visi贸n por computador**, **gr谩ficos por computadora** y **rob贸tica**, donde es necesario manipular im谩genes para an谩lisis, reconstrucci贸n o animaci贸n.

El objetivo de este ejercicio es implementar un programa en **Python** que cargue una imagen, aplique una serie de transformaciones geom茅tricas sucesivas y genere un **GIF animado** que muestre la secuencia de transformaciones aplicadas.

---

### Fundamento Te贸rico


Las transformaciones geom茅tricas son operaciones fundamentales en el **procesamiento digital de im谩genes**, ya que permiten modificar la posici贸n, orientaci贸n o tama帽o de los objetos dentro de una escena.

### a. Traslaci贸n:

Desplaza una imagen una distancia $(t_x, t_y)$ sobre los ejes $X$ y $Y$:

$$x' = x + t_x, \quad y' = y + t_y$$

### b. Rotaci贸n:

Gira la imagen un 谩ngulo $\theta$ respecto a un punto de referencia:

$$\begin{bmatrix} x' \\ y' \end{bmatrix} = \begin{bmatrix} \cos(\theta) & -\sin(\theta) \\ \sin(\theta) & \cos(\theta) \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix}$$

### c. Escalamento:

Aumenta o reduce el tama帽o de una imagen seg煤n un factor $s$:

$$x' = s_x \cdot x, \quad y' = s_y \cdot y$$

Combinadas, estas operaciones permiten realizar **transformaciones afines** que preservan las l铆neas y proporciones de la imagen original.



### Metodolog铆a

1. **Carga de la imagen original:**  
   Se utiliz贸 la librer铆a `PIL` para abrir y convertir la imagen a formato RGBA, garantizando compatibilidad con transparencia.

2. **Definici贸n de transformaciones:**  
   Se defini贸 una lista de diccionarios con los par谩metros de **rotaci贸n (rot)**, **traslaci贸n (tx, ty)** y **escala (scale)** para cada paso sucesivo.

3. **Aplicaci贸n secuencial:**  
   Para cada transformaci贸n:
   - Se reescal贸 la imagen.
   - Se rot贸 seg煤n el 谩ngulo indicado.
   - Se peg贸 sobre un fondo blanco, ajustando la posici贸n con traslaci贸n.

4. **Generaci贸n de frames:**  
   Cada imagen transformada se guard贸 como `frame_XX.png` en la carpeta `frames_temp/`.

5. **Creaci贸n del GIF:**  
   Finalmente, con `imageio.mimsave()` se combinan los cuadros en un GIF animado llamado **`transformaciones.gif`**.

---

### C贸digo Implementado

El siguiente script en Python aplica **transformaciones geom茅tricas** (rotaci贸n, traslaci贸n y escalamiento) a una imagen para generar un **GIF animado**.  
Adem谩s, incluye una verificaci贸n para evitar volver a ejecutar la funci贸n si los resultados ya existen.

---

### З C贸digo fuente

```python
def transformar_imagen(ruta_imagen, salida_gif="animacion.gif"):
    carpeta_frames = "frames_temp"

    #  Si ya existen los resultados, no ejecutar la funci贸n
    if os.path.exists(carpeta_frames) and os.path.exists(salida_gif):
        print("Las carpetas y el GIF ya existen. No se ejecutar谩 la funci贸n.")
        return

    # Crear carpeta temporal para los frames (solo si no existe)
    os.makedirs(carpeta_frames, exist_ok=True)

    # Cargar imagen original
    img_original = Image.open(ruta_imagen).convert("RGBA")
    ancho, alto = img_original.size

    # Lista para guardar los frames
    frames = []

    # Definir transformaciones (rotaci贸n, traslaci贸n, escala)
    transformaciones = [
        {"rot": 0,   "tx": 0,  "ty": 0,  "scale": 1.0},
        {"rot": 15,  "tx": 20, "ty": 0,  "scale": 1.1},
        {"rot": 30,  "tx": 40, "ty": 10, "scale": 1.2},
        {"rot": 60,  "tx": 60, "ty": 20, "scale": 1.1},
        {"rot": 90,  "tx": 80, "ty": 40, "scale": 0.9},
        {"rot": 120, "tx": 60, "ty": 60, "scale": 0.8},
        {"rot": 150, "tx": 40, "ty": 80, "scale": 0.9},
        {"rot": 180, "tx": 0,  "ty": 100,"scale": 1.0},
    ]

    for i, t in enumerate(transformaciones):
        # Aplicar escala
        nuevo_ancho = int(ancho * t["scale"])
        nuevo_alto = int(alto * t["scale"])
        img_transformada = img_original.resize((nuevo_ancho, nuevo_alto))

        # Aplicar rotaci贸n
        img_transformada = img_transformada.rotate(t["rot"], expand=True)

        # Crear fondo blanco
        fondo = Image.new("RGBA", (ancho * 2, alto * 2), (255, 255, 255, 255))

        # Calcular posici贸n
        x = ancho // 2 + t["tx"]
        y = alto // 2 + t["ty"]

        # Pegar imagen transformada
        fondo.paste(img_transformada, (x, y), img_transformada)

        # Guardar frame
        frame_path = os.path.join(carpeta_frames, f"frame_{i:02d}.png")
        fondo.save(frame_path)
        frames.append(imageio.v3.imread(frame_path))

    # Crear GIF con loop infinito
    imageio.mimsave(salida_gif, frames, duration=0.5, loop=0)

    print(f" GIF generado correctamente: {salida_gif}")
    print(f" Frames guardados en: {os.path.abspath(carpeta_frames)}")

# Ejemplo de uso 
# Primer parametro : Direccion de la imagen (Utilizaremos la imagen guardada en la carpeta images llamada 'Imagen_gif.jpeg' para utilzar otra simplemente cambiar la ruta)
# Segundo parametro : Como se llamara el gif (Importante poner .gif al final)
transformar_imagen("../images/Imagen_gif.jpeg", "transformaciones.gif")

```

---

### **Resultados**

![Secuencia de Transformaciones Geom茅tricas](Notebooks/transformaciones.gif)

- Se gener贸 correctamente el archivo **`transformaciones.gif`**, mostrando la secuencia de transformaciones aplicadas sobre la imagen original.  
- Los frames intermedios fueron almacenados en la carpeta **`frames_temp`**, permitiendo su inspecci贸n individual.
- El movimiento obtenido refleja un cambio progresivo en posici贸n, tama帽o y orientaci贸n de la figura, generando una animaci贸n fluida y continua.

**Archivos generados:**
```
frames_temp/frame_00.png
frames_temp/frame_01.png
...
frames_temp/frame_07.png
transformaciones.gif
```

---

### **An谩lisis**

El resultado demuestra la correcta aplicaci贸n de transformaciones afines en el plano bidimensional.  
Al combinar **rotaci贸n**, **traslaci贸n** y **escala**, se observa un efecto din谩mico que simula movimiento.  
Adem谩s, la funci贸n implementa un mecanismo de **control de ejecuci贸n** que evita repetir c谩lculos si los archivos ya existen, optimizando el flujo de trabajo.

**Aspectos destacados:**
- El uso de `expand=True` en la rotaci贸n evita recortes de la imagen.  
- La creaci贸n de un lienzo de fondo mayor garantiza que la imagen transformada siempre se mantenga visible.  
- El GIF permite visualizar la evoluci贸n progresiva de la imagen, siendo 煤til para comprender los efectos de cada transformaci贸n.


## 5. Implementar t茅cnicas fundamentales de segmentaci贸n de im谩genes.
Capturen una escena con objetos de colores distintos de la Universidad Nacional o de la oficina de alguno de los integrantes del equipo. Debe ser con una c谩mara de un tel茅fono celular.
- Segmenten cada objeto por su color
- Cuenten cu谩ntos objetos de cada color hay
- Calculen el 谩rea de cada objeto


### Soluci贸n

Para analizar una fotograf铆a de orqu铆deas capturada en la Universidad Nacional con un tel茅fono Motorola G30, se dise帽贸 un pipeline de visi贸n por computadora con el fin de superar el principal desaf铆o de la escena: el solapamiento y la oclusi贸n entre las flores.

**1. Segmentaci贸n de Objetos por Color**

El proceso inicia con la segmentaci贸n por color, convirtiendo la imagen al espacio **HSV** para robustez ante variaciones de luz. Se definieron categor铆as de color ('Rosa', 'Azul Pastel', 'Amarillo Quemado') y una clase especial ('Blancas') que agrupa los tonos blanco y rosa p谩lido mediante una operaci贸n l贸gica `cv2.bitwise_or`. Los rangos de color se establecieron con un m茅todo h铆brido: se tomaron valores base de la plataforma HTML Color Codes (2025) y se ajustaron emp铆ricamente analizando la fotograf铆a original.

**2. Conteo de Objetos**

Una vez aislados los objetos, se utiliz贸 el algoritmo `cv2.findContours` para detectar cada elemento individual. Sin embargo, para garantizar un conteo preciso, se implement贸 una l贸gica de refinamiento que:
* **Fusiona contornos:** Une fragmentos que pertenecen a un solo objeto pero que fueron detectados por separado.
* **Divide contornos:** Separa objetos que se tocan y fueron err贸neamente detectados como uno solo.

Este proceso de post-procesamiento asegura que el n煤mero final de objetos contados por color sea una representaci贸n fiel de la escena real.

**3. C谩lculo del rea de Cada Objeto**

Finalmente para que las mediciones tuvieran validez en el mundo real, se implement贸 un sistema de calibraci贸n de escala. Se tom贸 como referencia el di谩metro promedio de una flor de orqu铆dea, establecido en 10 cm seg煤n la literatura consultada (Jard铆n Bot谩nico de Medell铆n, 2024). El script mide este di谩metro de referencia en p铆xeles y calcula un factor de conversi贸n **(p铆xeles por cent铆metro)**. Finalmente, el 谩rea de cada objeto detectado, inicialmente calculada en p铆xeles con `cv2.contourArea()`, se convierte a **cent铆metros cuadrados (cm虏)** utilizando esta escala.

![Imagen de las flores utilizadas en el an谩lisis y resultados](images/DashBoardFlores.png)

### An谩lisis de Resultados
***

En esta secci贸n se eval煤a el rendimiento del pipeline de visi贸n por computadora implementado, comparando los resultados cuantitativos obtenidos por el script con una inspecci贸n manual de la imagen (Ground Truth). El objetivo es identificar tanto los aciertos como las limitaciones del modelo y proponer mejoras t茅cnicas.

#### Comparativa de Resultados: Predicci贸n vs. Realidad

| Categor铆a de Color | Cantidad Real (Ground Truth) | Cantidad Predicha (Modelo) | Precisi贸n |
| :----------------- | :--------------------------: | :------------------------: | :-------: |
| Rosa        |       7        |       7       | 100%   |
| Amarillo Quemado  |       7        |       8       | 87.5%  |
| Azul Pastel    |       1        |       1       | 100%   |
| Blanco       |       13       |       12       | 92.3%  |
| **Total** |      **28** |      **28** | **96.4%**|

*Nota: La precisi贸n se calcula como (Predichos Correctos / Total Real). Para el caso del Amarillo, 7 de 8 detecciones correspond铆an a flores reales.*

***
#### Discusi贸n de Aciertos y Desaf铆os

El modelo demostr贸 un alto rendimiento general, con una precisi贸n global del 96.4% en la identificaci贸n y conteo de objetos.

**Aciertos Notables:**

* Las categor铆as **Rosa** y **Azul Pastel** fueron identificadas con un 100% de precisi贸n. Esto valida que los rangos HSV definidos y la l贸gica de segmentaci贸n son altamente efectivos para objetos con colores bien definidos y formas consistentes.

**Desaf铆os y Puntos de Mejora:**

* **Flores Amarillas (Sobre-segmentaci贸n):** El modelo predijo 8 flores cuando en realidad hab铆a 7. El an谩lisis cualitativo revela que una 煤nica flor fue segmentada incorrectamente en dos partes, resultando en un conteo adicional. Este error de **sobre-segmentaci贸n** probablemente se deba a sombras pronunciadas o gradientes de color internos en la flor, que la l贸gica de divisi贸n interpret贸 err贸neamente como el l铆mite entre dos objetos.

* **Flores Blancas (Sub-segmentaci贸n y Detecci贸n de Bordes):** Se predijeron 12 flores de las 13 existentes. El error se origin贸 en la dificultad del modelo para definir correctamente los bordes de dos flores que presentaban una transici贸n de color compleja (de blanco marfil oscuro a rosa p谩lido). Esto caus贸 que una de las flores no fuera detectada en su totalidad, llevando a un error de **sub-segmentaci贸n**. La categor铆a 'Blancas', al combinar dos rangos de color, es inherentemente m谩s compleja y sensible a estas variaciones sutiles.

***
#### Mejoras Futuras Propuestas

1. **Refinar la L贸gica de Fusi贸n/Divisi贸n:** La divisi贸n basada en el rect谩ngulo delimitador es efectiva pero simple. Para evitar la sobre-segmentaci贸n (caso amarillo), se podr铆a implementar el **Algoritmo de Watershed**. Esta t茅cnica es m谩s robusta para separar objetos que se tocan, ya que se basa en la "topograf铆a" de la imagen en lugar de su geometr铆a simple.

2. **Mejorar la Segmentaci贸n de Colores Complejos:** Para el caso de las flores blancas, en lugar de combinar dos rangas con un `OR` l贸gico, se podr铆a explorar el uso de t茅cnicas de **clustering de color (como K-Means)** en regiones de inter茅s. Esto permitir铆a agrupar p铆xeles de manera m谩s inteligente, adapt谩ndose mejor a las transiciones de tono.

3. **Pre-procesamiento Adicional:** Aplicar un filtro de suavizado, como un **desenfoque gaussiano (Gaussian Blur)** de bajo nivel antes de la segmentaci贸n, podr铆a ayudar a homogeneizar las superficies de las flores. Esto reducir铆a el impacto de texturas y sombras internas, minimizando el riesgo de errores como el ocurrido con la flor amarilla.



## Referencias
GeeksforGeeks. (s.f.). *Camera Calibration with Python OpenCV*. https://www.geeksforgeeks.org/python/camera-calibration-with-python-opencv/

Reolink. (s.f.). Barrel Distortion: What It Is, and How to Fix It. Reolink Blog. https://reolink.com/blog/barrel-distortion/

OpenCV Development Team. (s.f.). Camera Calibration and 3D Reconstruction. Obtenido de la documentaci贸n oficial de OpenCV, m贸dulo calib3d.

Szeliski, R. (2021). Computer Vision: Algorithms and Applications (2.陋 ed.). Springer.

HTML Color Codes. (2025). HTML Color Codes. Recuperado el 19 de octubre de 2025, de https://htmlcolorcodes.com/es/

Jard铆n Bot谩nico de Medell铆n. (2024). *Ficha t茅cnica: Phalaenopsis amabilis*. Recuperado de https://www.jardinbotanicomedellin.org/orquideas/phalaenopsis


Gonzalez, R. C., & Woods, R. E. (2018). *Digital Image Processing (4th Edition)*. Pearson.  
Pillow Documentation: [https://pillow.readthedocs.io](https://pillow.readthedocs.io)  
ImageIO Documentation: [https://imageio.readthedocs.io](https://imageio.readthedocs.io)